import os
import yaml
import argparse
import torch

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from utils.builder import build_model, build_criterion, build_optimizer, build_evaluator
from utils.data_loader import get_dataloaders
from utils.trainer import Trainer

def main(args):
    # 1. åŠ è½½é…ç½®æ–‡ä»¶
    with open(args.config, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # 2. è®¾ç½®è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸ Using device: {device}")

    # 3. æ„å»ºæ¨¡å‹
    model = build_model(config).to(device)

    # 4. æ„å»ºæ•°æ®åŠ è½½å™¨
    # ä¼ å…¥ config_path æ–¹ä¾¿ get_dataloaders å†…éƒ¨è¯»å–è·¯å¾„å‚æ•°
    loaders = get_dataloaders(args.config)
    train_loader = loaders['train']
    val_loader = loaders['val']

    # 5. æ„å»ºæŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨å’Œè¯„ä»·æŒ‡æ ‡
    criterion = build_criterion(config)
    optimizer = build_optimizer(config, model)
    evaluator = build_evaluator(config)

    # 6. (å¯é€‰) æ„å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨ Scheduler
    # ä½¿ç”¨ ReduceLROnPlateau
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', 
        factor=config.get('scheduler', {}).get('factor', 0.5), 
        patience=config.get('scheduler', {}).get('patience', 5),
        min_lr=config.get('scheduler', {}).get('min_lr', 1e-6),
        cooldown=config.get('scheduler', {}).get('cooldown', 2),
    )

    # 7. å®ä¾‹åŒ– Trainer
    # è¿™é‡Œçš„å‚æ•°å¯¹åº”ä½ è¦æ±‚çš„ __init__ ç­¾å
    trainer = Trainer(
        model=model,
        optimizer=optimizer,
        criterion=criterion,
        device=device,
        train_loader=train_loader,
        val_loader=val_loader,
        evaluator=evaluator,
        scheduler=scheduler,
        save_dir=config.get('training', {}).get('save_dir', 'results'),
        patience=config.get('training', {}).get('patience', 10)
    )

    # 8. æ–­ç‚¹ç»­è®­é€»è¾‘ (Resume)
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸Šæ¬¡ä¸­æ–­çš„æƒé‡æ–‡ä»¶
    resume_path = os.path.join(config.get('training', {}).get('save_dir', 'results'), 'checkpoints', 'last.pth')
    
    if args.resume and os.path.exists(resume_path):
        print(f"ğŸ”„ Found checkpoint at {resume_path}, resuming...")
        trainer.fit(epochs=config['training']['epochs'], resume_path=resume_path)
    else:
        print("ğŸš€ Starting a fresh training...")
        trainer.fit(epochs=config['training']['epochs'])

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Training Script")
    
    # æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„
    parser.add_argument('--config', type=str, default='config.yaml', help='path to config file')
    
    # æ˜¯å¦å¼€å¯ç»­è®­æ¨¡å¼çš„å¼€å…³
    parser.add_argument('--resume', action='store_true', default=True,
                        help='resume from last checkpoint if exists')
    
    args = parser.parse_args()
    
    main(args)
